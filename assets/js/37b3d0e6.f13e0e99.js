"use strict";(globalThis.webpackChunkmomentum_website=globalThis.webpackChunkmomentum_website||[]).push([[4745],{65513:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>a,frontMatter:()=>t,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"developer_guide/design_decisions","title":"Design Decisions","description":"NumPy vs PyTorch Tensors","source":"@site/docs_python/03_developer_guide/02_design_decisions.md","sourceDirName":"03_developer_guide","slug":"/developer_guide/design_decisions","permalink":"/momentum/pymomentum/developer_guide/design_decisions","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/momentum/edit/main/momentum/website/docs_python/03_developer_guide/02_design_decisions.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Development Environment","permalink":"/momentum/pymomentum/developer_guide/development_environment"},"next":{"title":"PyPI Publishing Guide","permalink":"/momentum/pymomentum/developer_guide/pypi_publishing"}}');var r=i(74848),o=i(28453);const t={sidebar_position:2},c="Design Decisions",d={},l=[{value:"NumPy vs PyTorch Tensors",id:"numpy-vs-pytorch-tensors",level:2},{value:"Why the Mixed Approach?",id:"why-the-mixed-approach",level:3},{value:"Current State",id:"current-state",level:3},{value:"Future Directions",id:"future-directions",level:3}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"design-decisions",children:"Design Decisions"})}),"\n",(0,r.jsx)(n.h2,{id:"numpy-vs-pytorch-tensors",children:"NumPy vs PyTorch Tensors"}),"\n",(0,r.jsx)(n.p,{children:"PyMomentum mixes NumPy arrays and PyTorch tensors throughout the codebase. This explains the reasoning and current status."}),"\n",(0,r.jsx)(n.h3,{id:"why-the-mixed-approach",children:"Why the Mixed Approach?"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Old Reason (Historical):"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Auto-conversion from Eigen types to NumPy arrays works natively in pybind11"}),"\n",(0,r.jsx)(n.li,{children:"Can use Python buffer interface to wrap data without copies"}),"\n",(0,r.jsx)(n.li,{children:'PyTorch tensors are "more painful to work with" in pybind11'}),"\n",(0,r.jsx)(n.li,{children:"Used PyTorch only where differentiability was needed"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Internal Convention:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"PyTorch tensor = differentiable operation"}),"\n",(0,r.jsx)(n.li,{children:"NumPy array = non-differentiable operation"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"New Reason (Current):"}),"\nThe dependence on aten makes building Python code that uses torch.Tensor somewhat challenging compared to code that uses the basic buffer interface:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Blocking pymomentum usage in downstream projects"}),"\n",(0,r.jsx)(n.li,{children:"Preventing demonstration projects"}),"\n",(0,r.jsx)(n.li,{children:"Causing various compatibility problems"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"current-state",children:"Current State"}),"\n",(0,r.jsx)(n.p,{children:"The codebase is mixed which can be confusing because we're between approaches. Discussions are happening around:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Stripping all PyTorch from ",(0,r.jsx)(n.code,{children:"pymomentum.geometry"})]}),"\n",(0,r.jsxs)(n.li,{children:["Isolating differentiability (and hence PyTorch dependencies) in specific libraries, such as ",(0,r.jsx)(n.code,{children:"diff_solver"})]}),"\n",(0,r.jsxs)(n.li,{children:["Using ",(0,r.jsx)(n.code,{children:"GPU_character"})," for ML workloads instead"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Examples:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"solver2"})," uses NumPy arrays (not differentiable, PyTorch-independent)"]}),"\n",(0,r.jsx)(n.li,{children:"Batching support being removed from non-ML contexts (like rendering)"}),"\n",(0,r.jsx)(n.li,{children:"Rendering code will strip batch support for open sourcing"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"PyTorch advantages being lost:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Extra tensor manipulation functionality"}),"\n",(0,r.jsx)(n.li,{children:"Batching/unbatching support"}),"\n",(0,r.jsx)(n.li,{children:"But interfaces become more confusing for non-ML use"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"future-directions",children:"Future Directions"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Potential approach:"})," If you need batching + differentiability + GPU support, use ",(0,r.jsx)(n.code,{children:"GPU_character"})," instead of pymomentum. This would let us:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Strip enormous amounts of code from pymomentum"}),"\n",(0,r.jsx)(n.li,{children:"Fix build system issues"}),"\n",(0,r.jsx)(n.li,{children:"Simplify interfaces"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["(Obviously could only happen after open sourcing ",(0,r.jsx)(n.code,{children:"GPU_character"}),")"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Current recommendation:"})," Accept manual conversions between NumPy/PyTorch until the architecture stabilizes."]})]})}function a(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);